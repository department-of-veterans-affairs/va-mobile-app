"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[274],{4210:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"QA/index","title":"Quality assurance","description":"The role of QA within a software delivery team is to provide enough details about the software we\'re delivering, so that stakeholders can make informed decisions (about whether to release, how to prioritize a given bug, etc).","source":"@site/development/QA/index.md","sourceDirName":"QA","slug":"/QA/","permalink":"/va-mobile-app/development/QA/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Quality assurance"},"sidebar":"tutorialSidebar","previous":{"title":"Foundations","permalink":"/va-mobile-app/development/Design/Foundations"},"next":{"title":"UI automation testing","permalink":"/va-mobile-app/development/QA/QA process/UI automation testing/"}}');var s=i(74848),a=i(28453);const r={title:"Quality assurance"},o="How we work",l={},d=[{value:"When is our testing &quot;good enough&quot;?",id:"when-is-our-testing-good-enough",level:2},{value:"We stop preparing for testing activities when:",id:"we-stop-preparing-for-testing-activities-when",level:3},{value:"We stop testing when:",id:"we-stop-testing-when",level:3},{value:"Common misconception: QA makes the final decision",id:"common-misconception-qa-makes-the-final-decision",level:2},{value:"QA team meeting philosophy",id:"qa-team-meeting-philosophy",level:2},{value:"Meeting review",id:"meeting-review",level:2},{value:"Inhale and exhale",id:"inhale-and-exhale",level:2},{value:"Test strategy",id:"test-strategy",level:2},{value:"Features to test",id:"features-to-test",level:2},{value:"Who is responsible",id:"who-is-responsible",level:2},{value:"Testing methods",id:"testing-methods",level:2},{value:"Testing accounts and data",id:"testing-accounts-and-data",level:2},{value:"Bug tracking",id:"bug-tracking",level:2},{value:"Issue severity",id:"issue-severity",level:3},{value:"Impact definitions",id:"impact-definitions",level:4},{value:"Frequency definitions",id:"frequency-definitions",level:4},{value:"User-submitted Bug Reports",id:"user-submitted-bug-reports",level:3},{value:"Test activity reporting",id:"test-activity-reporting",level:2},{value:"Mobile QA Overview",id:"mobile-qa-overview",level:2}];function c(e){const t={a:"a",blockquote:"blockquote",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"how-we-work",children:"How we work"})}),"\n",(0,s.jsx)(t.p,{children:"The role of QA within a software delivery team is to provide enough details about the software we're delivering, so that stakeholders can make informed decisions (about whether to release, how to prioritize a given bug, etc)."}),"\n",(0,s.jsx)(t.p,{children:'We typically provide that information by signing off that we\'ve tested the software in question to our satisfaction. Saying "QA approves merging to develop" or "QA approves release" means we believe we\'ve tested the software well.'}),"\n",(0,s.jsx)(t.h2,{id:"when-is-our-testing-good-enough",children:'When is our testing "good enough"?'}),"\n",(0,s.jsx)(t.p,{children:'Good software testing happens with the keen awareness that it is impossible to "find all the bugs" (limitations in time, resources, tooling, and knowledge; not to mention inevitable changes in data, processes, software, and systems our software integrates with). Therefore, a highly-functional QA team knows when to stop vs continue working on a given task. On our team:'}),"\n",(0,s.jsx)(t.h3,{id:"we-stop-preparing-for-testing-activities-when",children:"We stop preparing for testing activities when:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"we are sufficiently aware of how our software and interacting systems can break and what kinds of problems are the most important to find, and"}),"\n",(0,s.jsx)(t.li,{children:"we have what we need (tools, data prep, etc) to be able to look for those problems."}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"we-stop-testing-when",children:"We stop testing when:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"we've examined the product commensurate to the risk it contains,"}),"\n",(0,s.jsx)(t.li,{children:"we've met our testing standards, and"}),"\n",(0,s.jsx)(t.li,{children:"we've expressed our testing plan and results, along with quality assessments, clearly."}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"common-misconception-qa-makes-the-final-decision",children:"Common misconception: QA makes the final decision"}),"\n",(0,s.jsx)(t.p,{children:"QA is one of the last roles, if not the last role, involved in a given ticket; on some teams they are given gatekeeping authority over what software is released."}),"\n",(0,s.jsx)(t.p,{children:"Within the VA mobile app space, PMs (in conjunction with stakeholders) make the final decision for what goes out the door. That is often explicit (such as new releases or new features) and, on a high-trust team, sometimes implicit (ex: QA stating a ticket meets the PM-set ACs does not need further review before merging into develop)"}),"\n",(0,s.jsx)(t.h1,{id:"meetings",children:"Meetings"}),"\n",(0,s.jsx)(t.h2,{id:"qa-team-meeting-philosophy",children:"QA team meeting philosophy"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Time and brainpower are the most important resources we manage as a QA team, because they are fundamental and finite. Where we spend our time and mental energy will determine what outcomes we can achieve."}),"\n",(0,s.jsx)(t.li,{children:"It's important for the QA team to attend meetings. We add value. We receive value. We bond with other folks on the team."}),"\n",(0,s.jsxs)(t.li,{children:["It's important for the QA team to ",(0,s.jsx)(t.em,{children:"not"})," go to meetings. Heads-down independent work is the time when we find bugs, improve processes, come up with novel testing strategies, etc."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"meeting-review",children:"Meeting review"}),"\n",(0,s.jsx)(t.p,{children:"Periodically re-evaluating which meetings we attend generally and who goes to each meeting specifically helps us to avoid over-spending time on meetings and to play to the strengths of individuals on the team. (Individuals can always talk with the team or their manager if they have changes they want to make to their own meeting workoad. The overall review process is meant as a backstop to look at everything holistically on a semi-regular basis.)"}),"\n",(0,s.jsx)(t.p,{children:"The goals of review are:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"For each individual on the team to be happy about the meetings they're attending. Ideally, everyone feels like they're going to the meetings where they give or receive the most value, or that match the best with their goals and skills."}),"\n",(0,s.jsxs)(t.li,{children:["For the team overall to be attending meetings efficiently. Ideally, we're spending ",(0,s.jsx)(t.em,{children:"just"})," enough time in meetings to meet our individual and team objectives, but no more than that. This could involve sending a representative (instead of multiple members of the team), keeping a recurring meeting on our calendar but only going when certain conditions are met, etc."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"inhale-and-exhale",children:"Inhale and exhale"}),"\n",(0,s.jsx)(t.p,{children:"To gain the same value out of meetings while each person attends fewer meetings requires a shared set of expectations for the sole QA representative attending any given meeting."}),"\n",(0,s.jsx)(t.p,{children:"Our expectations are that representatives will pay attention at the meeting (inhale) and share necessary information with the full team in our Slack channel (exhale). Examples of information we'd expect to share:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Times you spoke up in a meeting"}),"\n"]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"\u201cI had a lot of questions about how they\u2019re going to implement the calendar feature for appointments, seems like there\u2019s a lot of accessibility things to figure out there still.\u201d"}),"\n"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Things the whole team needs to know to do our jobs"}),"\n"]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"\u201cWe're pausing all work on this feature. Hold off on writing test plans for the areas we assigned out last week, until further notice.\""}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"When you\u2019re sensing a problem, or if there\u2019s something to keep an eye out for"}),"\n"]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:'\u201cMy first round of testing for the migration turned up way more issues than we expected. I confirmed changes with the testing plan with Eng and Product at the feature check-in, and the rest of the team can expect a meeting invitation to get up to speed (so you can also start testing) sometime this week."'}),"\n"]}),"\n",(0,s.jsx)(t.h1,{id:"quality-assurance-process",children:"Quality Assurance Process"}),"\n",(0,s.jsxs)(t.p,{children:["A quality assurance process is an agreement between the project developers, product managers and quality assurance on the process for testing and verifying the delivery of product functionality. (See ",(0,s.jsx)(t.a,{href:"https://www.altexsoft.com/whitepapers/quality-assurance-quality-control-and-testing-the-basics-of-software-quality-management/",children:"this whitepaper"}),' for some great QA-related basic terms and definitions, including "quality assurance process")']}),"\n",(0,s.jsx)(t.p,{children:"The VA Mobile App is a mobile application that will allow veterans to access their healthcare services and claims information via their mobile devices."}),"\n",(0,s.jsx)(t.p,{children:"The objective of this QA process is to document how we will verify that the software developed for the VA Mobile App works as defined in the product requirements."}),"\n",(0,s.jsx)(t.h2,{id:"test-strategy",children:"Test strategy"}),"\n",(0,s.jsxs)(t.p,{children:["We are taking an integrated approach to testing - building QA activities into the agile development process so that testing takes place early and often as a key part of sprint operations. Identifying issues during development will minimize technical and functional debt and make for better product quality and more accurate progress reporting and delivery status. In addition, we will leverage automated testing tools in the development delivery chain to provide real time ",(0,s.jsx)(t.a,{href:"https://department-of-veterans-affairs.github.io/va-mobile-app/development/FrontEnd/Testing",children:"unit"}),", ",(0,s.jsx)(t.a,{href:"https://department-of-veterans-affairs.github.io/va-mobile-app/development/QA/QA%20process/UI%20automation%20testing/",children:"UI"})," and service reliability (",(0,s.jsx)(t.em,{children:"no documentation yet"}),") checks."]}),"\n",(0,s.jsx)(t.h2,{id:"features-to-test",children:"Features to test"}),"\n",(0,s.jsx)(t.p,{children:"Testing will be performed throughout the development process based on the prioritization and delivery of features in the product backlog. As product management prioritizes features and the development team implements those features, Quality Assurance will write associated test cases and execute those test cases, verifying that the features delivered meet the requirements and function as intended. Features that have not been prioritized and implemented will not be tested. For a detailed description of test and acceptance criteria please refer to the product backlog. At a high level, testing will cover the following functionality:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"All delivered features related to login and authentication flows including biometric authentication"}),"\n",(0,s.jsx)(t.li,{children:"All delivered features related to navigation and general app behavior"}),"\n",(0,s.jsx)(t.li,{children:"All delivered features related to veteran access of information in the app (such as military history or disability rating)"}),"\n",(0,s.jsx)(t.li,{children:"All delivered features related to veteran submission of information in the app (such as Rx refill, secure messaging, or file upload in claims)"}),"\n",(0,s.jsx)(t.li,{children:"All delivered features related to notifications including push notifications"}),"\n",(0,s.jsx)(t.li,{children:"All delivered features using accessibility controls (see accessibility test plan for more detail)"}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"who-is-responsible",children:"Who is responsible"}),"\n",(0,s.jsxs)(t.p,{children:["Software quality is a team effort. Developers will be responsible for ",(0,s.jsx)(t.a,{href:"https://department-of-veterans-affairs.github.io/va-mobile-app/development/FrontEnd/Testing",children:"writing unit tests"}),". The product team will be responsible for user acceptance testing of the delivered features. Quality Assurance is responsible for writing automated UI tests and manually testing the product functionality and various user flows through the application."]}),"\n",(0,s.jsx)(t.h2,{id:"testing-methods",children:"Testing methods"}),"\n",(0,s.jsx)(t.p,{children:"The following testing methods will be employed during development and testing of the VA Mobile App."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Method"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Description"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Primary Owner"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"User Stories & Acceptance Criteria"}),(0,s.jsx)(t.td,{children:"Requirements are defined by the product team and written as user stories in the product backlog. Acceptance criteria (AC) are written as part of the user story and describe the conditions that must be met in order for the story to be accepted as complete."}),(0,s.jsx)(t.td,{children:"Product"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Test Cases & Functional Testing"}),(0,s.jsx)(t.td,{children:"Test cases are defined by the QA team and are written not only to make sure all stories and their acceptance criteria are met but will also account for edge cases (scenarios that happen outside of normal operating conditions) like attempting to upload the wrong file type or entering text characters into a date field. Test cases are used to perform manual functional testing in which QA interacts with the application as would an end user to identify any issues."}),(0,s.jsx)(t.td,{children:"QA"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Unit Testing"}),(0,s.jsx)(t.td,{children:"Unit tests are written into the code by developers and target the smallest components of the code that can be logically isolated from the rest of the system. These tests are typically fast and can run any time the code is changed to help identify and isolate defects during development. The purpose of unit tests is to make sure the code functions are defect-free before merging into the larger code base."}),(0,s.jsx)(t.td,{children:"Developers"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Integration Testing"}),(0,s.jsx)(t.td,{children:"In contrast to unit tests, integration tests run across individual modules of code to validate that separately developed modules are working together properly. Integration tests are also used to validate that the VA Mobile App front end interfaces with other systems and services, such as the VA.gov APIs, as designed."}),(0,s.jsx)(t.td,{children:"Developers"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"End-to-end Testing"}),(0,s.jsx)(t.td,{children:"End-to-end testing, or system testing, looks to validate that the system as a whole works as intended. These tests are similar in nature to integration tests but are focused on the superset of delivered software and its connections to other systems. End-to-end testing will be done prior to release and will consist of both manual and automated testing to ensure adequate coverage of the delivered functionality."}),(0,s.jsx)(t.td,{children:"Developers, QA, Product"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"User Acceptance Testing"}),(0,s.jsx)(t.td,{children:'User Acceptance Testing, sometimes referred to as "UAT" or just Acceptance Testing, involves the product team and other stakeholders interacting with the application to simulate real-world usage and signing off that the delivered software functions as defined in the designs and requirements. We will leverage pre-production distribution tools such as TestFlight to get the app in the hands of stakeholders to facilitate Acceptance Testing.'}),(0,s.jsx)(t.td,{children:"Product, Stakeholder community"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Accessibility Testing"}),(0,s.jsx)(t.td,{children:"Accessibility is a major requirement for the VA Mobile App and requires additional consideration beyond the standard testing process. QA will include accessibility checks in the manual functional testing activities. For a more detailed plan on accessibility testing approach see the [Mobile Accessibility Testing Plan](./QA Process/Accessibility Testing Plan.md)."}),(0,s.jsx)(t.td,{children:"Developers, QA"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Compatibility Testing"}),(0,s.jsxs)(t.td,{children:["Software may behave differently depending on the specific device and operating system that it is running on. In order to validate that the software developed will work as intended across a variety of devices we will also perform manual functional testing of each feature on a variety of physical devices and OSs as defined on the ",(0,s.jsx)(t.a,{href:"/va-mobile-app/development/QA/QA%20process/MobileOSSupport",children:"compatibility page"}),"."]}),(0,s.jsx)(t.td,{})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"testing-accounts-and-data",children:"Testing accounts and data"}),"\n",(0,s.jsx)(t.p,{children:"In order to support testing activities we will need test user accounts with test data that is representative of the variations anticipated in production user data. The purpose of test accounts and test data is to simulate the possible variations that may occur in production data to stress test the application and ensure it has been designed and built to accommodate real world user variance. Test user data variance, and uptime/availability of staging systems, is critical to efficient, low-risk delivery of new features and regression-testing existing features."}),"\n",(0,s.jsx)(t.h2,{id:"bug-tracking",children:"Bug tracking"}),"\n",(0,s.jsx)(t.p,{children:"Issues identified during a development sprint will be written up as new bug tickets, and attached to an epic (if relevant). The Product Owner may prioritize logged issues into upcoming sprints for the development team to address. Issue tickets are scoped at a 1 by default, and split into further tickets if Engineering investigation uncovers a heavier lift to fix than the default scoping."}),"\n",(0,s.jsxs)(t.p,{children:["All issue tickets should be written using the ",(0,s.jsx)(t.a,{href:"https://github.com/department-of-veterans-affairs/va-mobile-app/blob/develop/.github/ISSUE_TEMPLATE/bug-report.md",children:"issue ticket template"}),". Issues should be classified according to severity based on an agreed-upon scale."]}),"\n",(0,s.jsx)(t.h3,{id:"issue-severity",children:"Issue severity"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Severity"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Definition"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Critical (sev-1)"}),(0,s.jsx)(t.td,{children:"Issues with both HIGH impact and HIGH frequency"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"High (sev-2)"}),(0,s.jsx)(t.td,{children:"Issues with either HIGH impact and LOW frequency, or LOW impact and HIGH frequency"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Low (sev-3)"}),(0,s.jsx)(t.td,{children:"Issues with both LOW impact and LOW frequency"})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"impact-definitions",children:"Impact definitions"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Impact"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Definition"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Examples"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"High impact"}),(0,s.jsx)(t.td,{children:"Prevents user from completing a task and/or direct violation of WCAG guideline"}),(0,s.jsx)(t.td,{children:"Crashes, system hangs, file/data corruption, errors with no discoverable workaround, component doesn't function (i.e. broken link, button can't receive screen reader focus), etc."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Low impact"}),(0,s.jsx)(t.td,{children:"Does not prevent user from completing a task; or area we can improve, even if following WCAG guidelines"}),(0,s.jsx)(t.td,{children:"Typos, unclear messaging, repetitive information, errors with an easily discoverable workaround, button improperly labeled as a link, etc."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"frequency-definitions",children:"Frequency definitions"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Frequency"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Definition"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Examples"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"High frequency"}),(0,s.jsx)(t.td,{children:"Affects a component, screen, or action used by 15% or more of monthly users"}),(0,s.jsxs)(t.td,{children:["- Authentication/login ",(0,s.jsx)("br",{})," - Home page (including What's New and Encouraged Update) ",(0,s.jsx)("br",{})," - Category landing screens (Health, Benefits, Payments and Profile) ",(0,s.jsx)("br",{})," - Feature landing and child screens for most-used features (Prescriptions, Upcoming Appointments, and Secure Messaging) ",(0,s.jsx)("br",{})," - Feature landing and child screens for next-most-used features (Claims, Disability Rating, Letters, Payment History) ",(0,s.jsx)("br",{})," - Key actions from the features already listed: med refill, sending a message (new or reply), and downloading a letter (decision or any other kind)"]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Low frequency"}),(0,s.jsx)(t.td,{children:"Affects a component, screen, or action used by 14% or fewer of monthly users"}),(0,s.jsx)(t.td,{children:"All other all screens and app actions (upload file, change demographic info, etc) not listed in high frequency examples"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsxs)(t.em,{children:["Frequency examples informed by the ",(0,s.jsx)(t.a,{href:"https://lookerstudio.google.com/reporting/e28cd59a-b2e5-4f29-8ae4-a4eea6d23f9c/page/p_xatxe90k9c",children:"Flagship Mobile Monthly Report"})]})}),(0,s.jsx)(t.td,{}),(0,s.jsx)(t.td,{})]})]})]}),"\n",(0,s.jsx)(t.h3,{id:"user-submitted-bug-reports",children:"User-submitted Bug Reports"}),"\n",(0,s.jsx)(t.p,{children:'The Mobile QA team monitors various bug reporting mechanisms to better serve our user base. Some of these mechanisms include: App Stores, Email, and miscellaneous message services. We manually collect these issues and file them into our backlog for review and triage as, "user feedback."'}),"\n",(0,s.jsx)(t.p,{children:"We have four paths for an issue that is submitted:"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsx)(t.li,{children:"If the issue is repeated in customer reports or shows evidence in monitoring tools, but we are unable to replicate, we will hold the issue in our backlog as a documented open issue."}),"\n",(0,s.jsxs)(t.li,{children:['If we cannot replicate the issue or evidence points to strange transient network problems / isolated to a single user, we will label the issue as "',(0,s.jsx)(t.a,{href:"https://github.com/department-of-veterans-affairs/va-mobile-app/labels/Closed%20-%20Can%27t%20Repro",children:"Closed - Can't Repro"}),'" and close the issue.']}),"\n",(0,s.jsxs)(t.li,{children:['If we know the issue was previously fixed, we will label the issue as "',(0,s.jsx)(t.a,{href:"https://github.com/department-of-veterans-affairs/va-mobile-app/labels/Closed%20-%20Deployed%2FFixed",children:"Closed - Deployed/Fixed"}),'" and close the issue.']}),"\n",(0,s.jsx)(t.li,{children:"If we are able to replicate the issue it will be evaluated for severity and assigned to the proper team for remediation."}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"test-activity-reporting",children:"Test activity reporting"}),"\n",(0,s.jsx)(t.p,{children:"QA activities will primarily be tracked in ZenHub as commentary on sprint stories or logged issues."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Activity"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Summary"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Acceptance Criteria / Test Cases"})}),(0,s.jsx)(t.td,{children:"Added to ZenHub and associated to user stories"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Issue Tickets"})}),(0,s.jsx)(t.td,{children:"Maintained in ZenHub"})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"mobile-qa-overview",children:"Mobile QA Overview"}),"\n",(0,s.jsxs)(t.p,{children:["In April of 2023, we recorded an 'overview of Mobile QA' presentation ",(0,s.jsx)(t.a,{href:"https://github.com/department-of-veterans-affairs/va.gov-team/files/11348079/PDF.Mobile.app.release.process.QA.pdf",children:"(presentation slides as PDF)"})," with some VA stakeholders. Video clips for each (rough) topic include:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://user-images.githubusercontent.com/94404065/234995289-0e373312-d47a-43f7-8db7-60bcdf4902ba.mp4",children:"High-level diagram of QA process in feature implementation"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://user-images.githubusercontent.com/94404065/234995471-a0774258-0cbe-47e4-9041-4d476a25c131.mp4",children:"The dwindling tail of bug fixes at the end of feature implementation, aka the feature armadillo"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://user-images.githubusercontent.com/94404065/234995671-e25cb9c9-e267-4ff0-ad8f-445acee8f10b.mp4",children:"What QA tests on any given ticket"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://user-images.githubusercontent.com/94404065/234995746-f18e5a4c-fc62-4939-838d-86c9061ba2e1.mp4",children:"QA work outside of testing"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://user-images.githubusercontent.com/94404065/234995839-6aed1042-818d-4e00-b55d-d22923f0698c.mp4",children:"QA FAQs, aka elephants in the room"})}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>o});var n=i(96540);const s={},a=n.createContext(s);function r(e){const t=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(a.Provider,{value:t},e.children)}}}]);